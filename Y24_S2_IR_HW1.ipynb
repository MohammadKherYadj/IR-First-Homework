{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMo1mViyyLBc"
      },
      "source": [
        "# وظيفة 1:\n",
        "\n",
        "Name1 : محمد خير راتب يدج\n",
        "\n",
        "ID1 : 021041854\n",
        "\n",
        "Name2 : علي محمد درويش\n",
        "\n",
        "ID2 : 020041662"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0D_9Tn5yIlR"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "HvYURUu4w4GB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "import arabic_reshaper\n",
        "import arabicstopwords.arabicstopwords as stp\n",
        "import re\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "\n",
        "from ar_corrector.corrector import Corrector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJHJkxI2yyKT"
      },
      "source": [
        "## Prepare classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnYuMPSUy4Sy"
      },
      "source": [
        "### Preprcessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE2V8L3ySmzr"
      },
      "source": [
        "#### Task-1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "90idV23hyxT2"
      },
      "outputs": [],
      "source": [
        "#-preprocessor\n",
        "class Preprocessor():\n",
        "    @staticmethod\n",
        "    def process(sentence):\n",
        "        print(\"The Result is :\")\n",
        "        s = Preprocessor.normDocument(sentence)\n",
        "        s = Preprocessor.removestopwords(s)\n",
        "        s = Preprocessor.stemDocument(s)\n",
        "        # s = Preprocessor.lemmatizDocument(s)\n",
        "        # s = Preprocessor.correctDocument(s)\n",
        "        return Preprocessor.tokenizeDocument(s)\n",
        "    \n",
        "    @staticmethod\n",
        "    def tokenizeDocument(sentance):\n",
        "        tokenizer = WhitespaceTokenizer()\n",
        "        return tokenizer.tokenize(sentance)\n",
        "    \n",
        "    @staticmethod\n",
        "    def removestopwords(sentence):\n",
        "        terms=set()\n",
        "        stopWords= set(stp.stopwords_list())\n",
        "        for term in Preprocessor.tokenizeDocument(sentence) :\n",
        "            if term not in stopWords :\n",
        "                terms.add(term)\n",
        "        terms = list(terms)\n",
        "        return \" \".join(terms)\n",
        "    \n",
        "    @staticmethod\n",
        "    def stemDocument(sentence):\n",
        "        ar_stemmer = stemmer(\"arabic\")\n",
        "        return \" \".join([ar_stemmer.stemWord(i) for i in Preprocessor.tokenizeDocument(sentence)])    \n",
        "\n",
        "    @staticmethod\n",
        "    def normDocument(sentence):\n",
        "        text = re.sub(\"[إأٱآا]\", \"ا\", sentence)\n",
        "        text = re.sub(\"ى\", \"ي\", text)\n",
        "        text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
        "        text = re.sub(\"ؤ\", \"ء\", text)\n",
        "        text = re.sub(\"ئ\", \"ء\", text)\n",
        "        text = re.sub(\"ة\", \"ه\", text)\n",
        "        return(text)\n",
        "    \n",
        "    @staticmethod\n",
        "    def correctDocument(sentance):\n",
        "        corr = Corrector() \n",
        "        terms = []\n",
        "        return \" \".join([corr.spell_correct(term) for term in Preprocessor.tokenizeDocument(sentance)])\n",
        "        # for term in Preprocessor.tokenizeDocument(sentance):\n",
        "        #     terms.append(corr.spell_correct(term))\n",
        "        # return \" \".join([term for term in terms])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "d1 = \"برنامج تعليمي للغة الإنجليزية ومسار سريع\"\n",
        "d2 = \"تعلم الفهرسة الدلالية الكامنة\"\n",
        "d3 = \"الكتاب في الفهرسة الدلالية\"\n",
        "d4 = \"التقدم في البنية و الفهرسة الدلالية\"\n",
        "d5 = \"تحليل تحليل البنية الكامنة\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Result is :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['مسار', 'رنامج', 'للغه', 'انجليزيه', 'تعليم', 'سريع']"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preprocessor.process(\".ذهبت, إلي. الغابة\")\n",
        "Preprocessor.process(d1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgzfEAQzK-v"
      },
      "source": [
        "### TDIM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsvCDB3MqvXB"
      },
      "source": [
        "#### Task-2:\n",
        "\n",
        "قم بالتعديل على باني الكلاس\n",
        "\n",
        "IndexModel\n",
        "\n",
        "بحيث يصبح نوع الفهرس المستخدم  من نمط معطيات جدول, أي\n",
        "\n",
        "data type of the attribute \"_index\" is DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SQVYjKEIzNbp"
      },
      "outputs": [],
      "source": [
        "#- Index Model : Term Document Incidence Matrix\n",
        "class IndexModel:\n",
        "\n",
        "    def __init__(self, documents_df):\n",
        "        print(\"question-2.1\")\n",
        "        self._index = {}\n",
        "        termdoc = documents_df.to_dict('list')\n",
        "        for term in termdoc:\n",
        "            termlist = []\n",
        "            i = 0\n",
        "            for term in termdoc:\n",
        "               i +=1\n",
        "            termlist.append((termdoc[\"id\"],i))\n",
        "            self._index[term] = termlist\n",
        "\n",
        "\n",
        "    def term_incidence_vector(self, term):\n",
        "        print(\"question-2.2\")\n",
        "        # اكتب اجابتك هنا\n",
        "        #return ...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# { \n",
        "#   \"term1\" : [(d1,5), (d2,1), (d5,7)],\n",
        "#   \"term2\" : [(d3,3), (d4,6), (d5,2)],\n",
        "#   \"term3\" : [(d1,2), (d2,7), (d3,6)],\n",
        "#  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question-2.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.IndexModel at 0x168f9815590>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = IndexModel(documents_df = loadDocuments())\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35spCMQ9rtRd"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TNPN8TnvruIj"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Retriever:\n",
        "    def __init__(self):\n",
        "        self._terms_operator = ['&', '|', '~']\n",
        "\n",
        "    def _merge(self, l1, l2):\n",
        "        res = []\n",
        "        i1 = 0; i2 = 0\n",
        "        while i1 < len(l1) and i2 < len(l2):\n",
        "            if l1[i1]==l2[i2]:\n",
        "                res += [l1[i1]]\n",
        "                i1 += 1; i2 += 1\n",
        "            elif l1[i1]<l2[i2]:\n",
        "                i1 += 1\n",
        "            elif l2[i2]<l1[i1]:\n",
        "                i2 += 1\n",
        "        return res\n",
        "\n",
        "    def boolean_operator_processing(self, bop, prevS, nextS=None, docidlist= None):\n",
        "        if bop == \"&\":\n",
        "            return self._merge(prevS, nextS)\n",
        "        elif bop==\"|\" :\n",
        "            return list(set(prevS+nextS))\n",
        "        elif bop == \"~\":\n",
        "            return [a for a in docidlist if a not in prevS]\n",
        "\n",
        "    def retrieve(self, query_terms, index_model):\n",
        "        ret_docs = []\n",
        "        bitwiseop=\"\"\n",
        "        result=[]\n",
        "        has_previous_term=False\n",
        "        has_not_operation=False\n",
        "        inc_vec_prev=[]\n",
        "        inc_vec_next=[]\n",
        "        for term in query_terms:\n",
        "            if term not in self._terms_operator:\n",
        "                if has_not_operation:\n",
        "                    if has_previous_term:\n",
        "                        inc_vec_next=self.boolean_operator_processing(bop=\"~\",prevS=index_model.term_postings(term),nextS=inc_vec_next, docidlist=index_model.getdi())\n",
        "                    else :\n",
        "                        inc_vec_prev=self.boolean_operator_processing(bop=\"~\",prevS=index_model.term_postings(term),nextS=inc_vec_next, docidlist=index_model.getdi())\n",
        "                        result=inc_vec_prev\n",
        "                    has_not_operation=False\n",
        "                elif has_previous_term:\n",
        "                    inc_vec_next=index_model.term_postings(term)\n",
        "                else:\n",
        "                    inc_vec_prev=index_model.term_postings(term)\n",
        "                    result= inc_vec_prev\n",
        "                    has_previous_term=True\n",
        "            elif term ==\"~\":\n",
        "                has_not_operation=True\n",
        "            else:\n",
        "                bitwiseop=term\n",
        "\n",
        "            #----------\n",
        "            if len(inc_vec_next)!= 0  :\n",
        "                result = self.boolean_operator_processing(bop=bitwiseop,prevS=inc_vec_prev,nextS=inc_vec_next, docidlist=index_model.getdi())\n",
        "                inc_vec_prev=result\n",
        "                has_previous_term=True\n",
        "                inc_vec_next= []\n",
        "\n",
        "        #-----\n",
        "        for res in result:\n",
        "            ret_docs.append({'docno':res, 'score':1})\n",
        "        ret_docs = pd.DataFrame(ret_docs, columns=['docno', 'score', 'content']).sort_values(by=['score'], ascending=False)\n",
        "        return ret_docs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mi2vBaQsAt2"
      },
      "source": [
        "### search engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DfCwzu5xr-oI"
      },
      "outputs": [],
      "source": [
        "class SearchEngine:\n",
        "    def __init__(self, preprocessor, retriever, documents):\n",
        "        self.preprocessor = preprocessor\n",
        "        self.retriever = retriever\n",
        "        self.documents = None\n",
        "        self.model = None\n",
        "        self.rebuild(documents)\n",
        "\n",
        "    def rebuild(self, documents):\n",
        "        self.documents = documents\n",
        "        self.documents['ntext'] = self.documents['text'].apply(self.preprocessor.process)\n",
        "        self.model = IndexModel(self.documents)\n",
        "\n",
        "    def querying(self, query):\n",
        "        query_terms = self.preprocessor.process(query)\n",
        "        docs_res = self.retriever.retrieve(query_terms, self.model)\n",
        "        if docs_res.shape[0]>0:\n",
        "            docs_res['content'] = docs_res.apply(\n",
        "                lambda row: self.documents[self.documents['id']==row.id]['text'].iloc[0], axis = 1)\n",
        "        return docs_res\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgJag5izsMVM"
      },
      "source": [
        "## Build and use the IRS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-PQ7fwXsY1Y"
      },
      "source": [
        "#### Task-3:\n",
        "\n",
        "انشئ جدول وثائق من مجموعة العبارات التالية\n",
        "\n",
        "\n",
        "1. برنامج تعليمي للغة الإنجليزية ومسار سريع\n",
        "2. تعلم الفهرسة الدلالية الكامنة\n",
        "3. الكتاب في الفهرسة الدلالية\n",
        "4. التقدم في البنية والفهرسة الدلالية\n",
        "5. تحليل تحليل البنية الكامنة\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FodJ81IxsN2m"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>برنامج تعليمي للغة الإنجليزية ومسار سريع</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>تعلم الفهرسة الدلالية الكامنة</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>الكتاب في الفهرسة الدلالية</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>التقدم في البنية والفهرسة الدلالية</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>تحليل تحليل البنية الكامنة</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                      text\n",
              "0   0  برنامج تعليمي للغة الإنجليزية ومسار سريع\n",
              "1   1             تعلم الفهرسة الدلالية الكامنة\n",
              "2   2                الكتاب في الفهرسة الدلالية\n",
              "3   3        التقدم في البنية والفهرسة الدلالية\n",
              "4   4                تحليل تحليل البنية الكامنة"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d1 = \"برنامج تعليمي للغة الإنجليزية ومسار سريع\"\n",
        "d2 = \"تعلم الفهرسة الدلالية الكامنة\"\n",
        "d3 = \"الكتاب في الفهرسة الدلالية\"\n",
        "d4 = \"التقدم في البنية والفهرسة الدلالية\"\n",
        "d5 = \"تحليل تحليل البنية الكامنة\"\n",
        "\n",
        "def loadDocuments():\n",
        "    return pd.DataFrame([\n",
        "        [0,d1],\n",
        "        [1,d2],\n",
        "        [2,d3],\n",
        "        [3,d4],\n",
        "        [4,d5],\n",
        "    ],columns=[\"id\",\"text\"])\n",
        "df = loadDocuments()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sobZu31tbvj"
      },
      "source": [
        "#### Task-4:\n",
        "\n",
        "انشئ كيان من نظام محرك البحث"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "npwIX3PWtktw"
      },
      "outputs": [],
      "source": [
        "# اكتب اجابتك هنا\n",
        "#ir_sys = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIffiofYtwT8"
      },
      "source": [
        "#### Task-5:\n",
        "\n",
        "اعرض اخر 3 وثائق\n",
        "\n",
        "واعرض حجم المصفوفة TDIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hnR2LCeGt4lv"
      },
      "outputs": [],
      "source": [
        "# اخر 3 وثائق\n",
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YiwIldSqM5yP"
      },
      "outputs": [],
      "source": [
        "# حجم مصفوفة وجود الكلمات في الوثائق TDIM\n",
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-nT25quEZm"
      },
      "source": [
        "#### Task-6:\n",
        "\n",
        "قم بعرض الوثائق الموافقة للاستعلامات التالية"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Ix1cqhlusP"
      },
      "source": [
        "Query-1 = \"التقدم & البنية & ~ تحليل\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QhoCpEB9uIRW"
      },
      "outputs": [],
      "source": [
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwIIbQv5lTsL"
      },
      "source": [
        "Query-2 = \"الكامنة & ~ تعليمي\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rfvLMB4rlbMJ"
      },
      "outputs": [],
      "source": [
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX5Y5guBlbpm"
      },
      "source": [
        "Query-3 = \"التقدم والبنية بدون تحليل\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4iuc5FPplcVX"
      },
      "outputs": [],
      "source": [
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccskZGjclc0K"
      },
      "source": [
        "Query-4 = \"تعلم | تحليل & الكامنة\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9UW0KIToldMR"
      },
      "outputs": [],
      "source": [
        "# اكتب اجابتك هنا\n",
        "#..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
